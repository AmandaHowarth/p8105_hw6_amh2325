---
title: "HW6"
author: "Amanda Howarth"
date: "11/23/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rvest)
library(tidyverse)
library(purrr)
library(broom)
library(modelr)
library(mgcv)
library(patchwork)
```

## Importing data
```{r}
birthweight = read_csv("./data/birthweight.csv")
```
## Cleaning data 
```{r}
birthweight_clean = birthweight %>% 
  janitor::clean_names() %>% 
  mutate(babysex = factor(babysex, levels = c("1", "2")),
         frace = factor(frace, levels = c("1", "2", "3", "4", "8", "9")),
         mrace = factor(mrace, levels = c("1", "2", "3", "4", "8", "9")),
         malform = factor(malform, levels = c("0", "1")),
         babysex = recode(babysex, "1" = "male", "2" = "female"), 
         frace = recode(frace, "1" = "white", "2" = "black", "3" = "asian", "4" = "puerto rican", "8" = "other", "9" = "unknown"),
         mrace = recode(mrace, "1" = "white", "2" = "black", "3" = "asian", "4" = "puerto rican", "8" = "other", "9" = "unknown"), 
         malform = recode(malform, "0" = "absent", "1" = "present")) %>%
  rename(bwt_grams = bwt, mom_weight_lbs = delwt, family_income = fincome, father_race = frace, mom_race = mrace, ges_age_weeks = gaweeks, age_menarche = menarche, mom_height = mheight, mom_age = momage, mom_pre_bmi = ppbmi)
```

## Model building
I have hypothesized that a baby's physical and biological characteristics as well as the mother's physical and biological characteristics at the time of delivery would affect the baby's weight at birth. Thus, in building my model I analyzed baby's sex, head circumference, baby length, gestational age, and presence of malformations that would affect weight. Additionally, I analyzed mother's weight, age at delivery, and height. 

```{r}
fit_bwt_model = lm(bwt_grams ~ babysex + bhead + blength + mom_weight_lbs + ges_age_weeks, data = birthweight_clean)

fit_bwt_model %>% 
  broom::tidy() %>% 
  knitr::kable()

fit_bwt_model %>%
  broom::glance() %>% 
  knitr::kable()
```

In my final model, I chose to include five final variables that I deemed to be clinically significant in predicting baby weight at birth: `babysex`, `bhead`, `blength`, `mom_weight_lbs`, and `ges_age_weeks`.I did not include `malform` (malformations that would affect weight) because its p-value was not statistically significant. However, for all other variables included in the final model above, they are statistically significant. I also analyzed the variables for `mom_age` and `mom_height` in the model, but they did not affect the R squared value (did not increase or decrease). I believe the five variables included in `fit_bwt_model` allow the model to be parsimonious while optimizing R^2. The value of R^2 is 0.6964, meaning 69.64% of the variability in birthweight is explained by: a baby's sex, baby's head circumference at birth, baby's length at birth, mother's weight at delivery, and gestational age in weeks. 


## Show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.
```{r}
birthweight_clean %>% 
  modelr::add_residuals(fit_bwt_model) %>% 
  modelr::add_predictions(fit_bwt_model) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point() + labs(
    y = "Residuals", 
    x = "Predicted values of Birthweight", 
    title = "Residuals Plotted Against Birthweight"
    
  )
```

## Model using using length at birth and gestational age as predictors (main effects only)
```{r}
sample_model_1 = lm(bwt_grams ~  blength + ges_age_weeks, data = birthweight_clean)

sample_model_1 %>% 
  broom::tidy() %>% 
  knitr::kable()

sample_model_1 %>% 
  broom::glance() %>% 
  knitr::kable()
```

The R^2 value in `sample_model1` (0.5769) is less than in `fit_bwt_model`. Thus, the variability in birthweight is better explained by `fit_bwt_model`.

## Model using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
sample_model_2 = lm(bwt_grams ~ bhead + blength + babysex + bhead*blength + bhead*babysex + babysex*blength + bhead*blength*babysex, data = birthweight_clean)

sample_model_2 %>% 
  broom::tidy() %>% 
  knitr::kable()

sample_model_2 %>% 
  broom::glance() %>% 
  knitr::kable()
```

The R^2 value in `sample_model1` (0.6849) is less than in `fit_bwt_model` (although the values are very similar). The variability in birthweight is better explained by `fit_bwt_model`.

## Cross Validation 
```{r}
cv_df = 
  crossv_mc(birthweight_clean, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)
         ) %>% 
  mutate(fit_bwt_model = map(train, ~lm(bwt_grams ~ babysex + bhead + blength + mom_weight_lbs + ges_age_weeks, data = .x)), 
         sample_model_1= map(train, ~lm(bwt_grams ~ blength + ges_age_weeks, data = .x)),
         sample_model_2= map(train, ~lm(bwt_grams ~ bhead + blength + babysex + bhead*blength + bhead*babysex + babysex*blength + bhead*blength*babysex, data = .x))) %>%
  mutate(rmse_1 = map2_dbl(fit_bwt_model, test, ~rmse(model = .x, data = .y)),
         rmse_2 = map2_dbl(sample_model_1, test, ~rmse(model = .x, data = .y)),
         rmse_3 = map2_dbl(sample_model_2, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin() + labs(
    y = "Root Mean Squared Errors", 
    x = "Models", 
    title = "Root Mean Squared Errors (RMSE's) Across Models"
  )

```

Through cross validation, we find that the first model (fit_bwt_model) has the lowest Root Mean Squared Error of all three models, indicating this model would be a better fit for this data. 


## Problem 2
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

## Drawing repeated samples with replacement.
```{r}
boot_sample = function(df) {
  sample_frac(weather_df, replace = TRUE)
}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )
boot_straps
```

## Analyzing bootstrap samples: Log(B0 * B1)
```{r}
bootstrap_results1 = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(cols = c(results)) %>% 
  select(strap_number, term, estimate) %>%
  pivot_wider(
    names_from = "term", 
    values_from = "estimate") %>%
  janitor::clean_names() %>% 
  mutate(log_estimate = log(intercept*tmin)) %>% 
  select(log_estimate)
```

## Analyzing bootstrap samples: R^2
```{r}
bootstrap_results2 = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>% 
      select(-strap_sample, -models) %>% 
  unnest(cols = c(results)) %>% 
  select(r.squared)
```

## Plot the distribution of your estimates, and describe these in words. 
```{r}
plot_log_estimate = bootstrap_results1 %>% 
   ggplot(aes(x = log_estimate)) + geom_histogram() + labs(
    y = "Count", 
    x = "Log(B_0 * B_1)", 
    title = "Distribtuion of Log(B_0 * B_1)"
  )

plot_r_squared = bootstrap_results2 %>% 
  ggplot(aes(x = r.squared)) + geom_histogram() + labs(
    y = "Count", 
    x = "R Squared", 
    title = "Distribtuion of R Squared ")

plot_log_estimate + plot_r_squared 
```
Both distributions above appear to be relatively symmetric. Thus, the left and right hand sides seem to nearly mirror each other within the histograms. There is very slight left skew present in the histogram of R-squared. Because the distribution is approximately symmetric for the histogram of the log of B0 * B1, the mean, median, and mode would all be approximately equal to 2.01 for log of B0*B1. 
For the histogram of R-squared, I will assume the histogram approximately follows a symmteric distribution, and thus its mean, median and mode would be the same value of ~0.91. 

Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂ 2 and log(β̂ 0∗β̂ 1)
```{r}
quantile(pull(bootstrap_results1, log_estimate), c(.0275, .975)) 

quantile(pull(bootstrap_results2, r.squared), c(.0275, .975)) 
```
From the results above, we see that the 95% confidence interval for the estimate of the  log(β̂ 0∗β̂1) is between 1.967 and 2.059.

From the results above, we see that the 95% confidence interval for the estimate of the  log(β̂ 0∗β̂1) is between 0.895 and 0.927. 



